{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10361bbd",
   "metadata": {},
   "source": [
    "# New metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de49564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "144eb09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_path = os.path.join('C:/', 'Users', 'Colin', 'Desktop', 'metrics_full_final')\n",
    "\n",
    "datasets_directories = [f.path for f in os.scandir(metrics_path) if f.is_dir()]\n",
    "datasets_names = [dataset_directory.split(os.path.sep)[-1] for dataset_directory in datasets_directories]\n",
    "datasets_names = sorted(datasets_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d8c06",
   "metadata": {},
   "source": [
    "#### Source for the student t test : https://machinelearningmastery.com/how-to-code-the-students-t-test-from-scratch-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d435a12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    dataset_name  DecisionTree Khiops  LinearRegression  RandomForest  XGBoost\n",
      "0   3D_Road_Netw             1      1                 1             1        1\n",
      "1   Air_Quality_             1      1                 1             0        0\n",
      "2   Airfoil_Self             1      1                 1             0        0\n",
      "3   Appliances_e             1      1                 1             1        1\n",
      "4   Beijing_PM2.             1      1                 1             1        1\n",
      "5   Bias_correct             1      1                 1             1        1\n",
      "6   Bike_Sharing             1      1                 1            -1       -1\n",
      "7   BlogFeedback             0      1                 1            -1       -1\n",
      "8   Buzz_in_soci             1      1                 1            -1       -1\n",
      "9   Combined_Cyc             1      1                 1             0        0\n",
      "10  Communities_             1      0                 0             0        0\n",
      "11  Communities_             1      1                 0             0        0\n",
      "12  Concrete_Com             1      1                 1             0        0\n",
      "13  Condition_Ba             1      1                 1             0        0\n",
      "14  Cuff-Less_Bl            -1     -1                 1            -1       -1\n",
      "15  Electrical_G             1      1                 1             1       -1\n",
      "16  Facebook_Com             1      1                 1            -1       -1\n",
      "17  Geographical             1      0                 1             0        0\n",
      "18  Greenhouse_G            -1      1                 1            -1       -1\n",
      "19  Individual_h             1    n/a                 1            -1       -1\n",
      "20  KEGG_Metabol             1      1                 1             0        0\n",
      "21  KEGG_Metabol             1      1                 1             1        1\n",
      "22  Online_News_             0     -1                 0            -1       -1\n",
      "23  Online_Video             1      1                 1             0        1\n",
      "24  PM2.5_Data_o             1      1                 1             0        0\n",
      "25  Parkinsons_T             1      1                 1             0        0\n",
      "26  Physicochemi             1      1                 1             1        1\n",
      "27  Production_q             1      1                 1             0        0\n",
      "28  Relative_loc             1      1                 0             1        1\n",
      "29  SGEMM_GPU_ke            -1      1                 1            -1       -1\n",
      "30  SML2010_Data             1      1                 1             1        1\n",
      "31  Seoul_Bike_S             1      1                 1             0        0\n",
      "32  UJIIndoorLoc             1      1                 1             0        0\n",
      "33  Uber_locatio             1      1                 1             0        0\n",
      "34  YearPredicti             1      1                 1             0       -1\n"
     ]
    }
   ],
   "source": [
    "regressor_names = ['DecisionTree', 'Khiops', 'LinearRegression', 'RandomForest', 'XGBoost']\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "metrics_dict = {'dataset_name': [e[:12] for e in datasets_names]}\n",
    "\n",
    "for regressor_name in regressor_names:\n",
    "    metrics_dict[regressor_name] = []\n",
    "    \n",
    "    for dataset_name in datasets_names:\n",
    "        base_df_path = os.path.join(metrics_path, dataset_name, '2_bins_equal_freq_below_threshold', 'Standard', regressor_name + '_regressor', 'metrics_normal.csv')\n",
    "        new_df_path = os.path.join(metrics_path, dataset_name, '32_bins_equal_freq_below_threshold', 'RandomForest_classifier', regressor_name + '_regressor', 'metrics_extracted_features.csv')\n",
    "        \n",
    "        # If the result file is missing add 'not available' instead of win/loss/defeat\n",
    "        if not (os.path.isfile(base_df_path) and os.path.isfile(new_df_path)):\n",
    "            metrics_dict[regressor_name].append('n/a')\n",
    "        \n",
    "        else:\n",
    "            tmp_base_rmse_df = pd.read_csv(base_df_path)\n",
    "            tmp_new_rmse_df = pd.read_csv(new_df_path)\n",
    "\n",
    "            # These lists are the RMSEs of each split\n",
    "            base_rmse_population = np.array(tmp_base_rmse_df['test_root_mean_squared_error'])\n",
    "            new_rmse_population = np.array(tmp_new_rmse_df['test_root_mean_squared_error'])\n",
    "\n",
    "            # Calculate the means\n",
    "            base_mean = np.mean(base_rmse_population)\n",
    "            new_mean = np.mean(new_rmse_population)\n",
    "\n",
    "            # Number of paired samples\n",
    "            n = len(base_rmse_population)\n",
    "\n",
    "            # Sum squared difference between observations\n",
    "            d1 = sum([(base_rmse_population[i] - new_rmse_population[i])**2 for i in range(n)])\n",
    "            # Sum difference between observations\n",
    "            d2 = sum([base_rmse_population[i] - new_rmse_population[i] for i in range(n)])\n",
    "\n",
    "            # Standard deviation of the difference between means\n",
    "            sd = math.sqrt((d1 - (d2**2 / n)) / (n - 1))\n",
    "\n",
    "            # Standard error of the difference between the means\n",
    "            sed = sd / math.sqrt(n)\n",
    "\n",
    "            # Calculate the t statistic\n",
    "            t_stat = (base_mean - new_mean) / sed\n",
    "\n",
    "            # Degrees of freedom\n",
    "            df = n - 1\n",
    "\n",
    "            # Calculate the critical value\n",
    "            cv = scipy.stats.t.ppf(1.0 - alpha, df)\n",
    "\n",
    "            # Calculate the p-value\n",
    "            p = (1.0 - scipy.stats.t.cdf(abs(t_stat), df)) * 2.0\n",
    "\n",
    "            # print everything\n",
    "            # print('t_stat = {0:.3f}'.format(t_stat), 'df =', df, 'cv = {0:.3f}'.format(cv), 'p = {0:.6f}'.format(p))\n",
    "\n",
    "            # Interpret via p-value\n",
    "            if p > alpha:\n",
    "                # Accept null hypothesis that the means are equal.\n",
    "                metrics_dict[regressor_name].append(0)\n",
    "            else:\n",
    "                # Reject the null hypothesis that the means are equal.\n",
    "                if base_mean < new_mean: # '<' because we are comparing RMSEs\n",
    "                    # Defeat\n",
    "                    metrics_dict[regressor_name].append(-1)\n",
    "                else:\n",
    "                    # Victory\n",
    "                    metrics_dict[regressor_name].append(1)\n",
    "\n",
    "print(pd.DataFrame(metrics_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "849b3432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree\n",
      "defeats = 3 equalities = 2 victories = 30\n",
      "Khiops\n",
      "defeats = 2 equalities = 2 victories = 30\n",
      "LinearRegression\n",
      "defeats = 0 equalities = 4 victories = 31\n",
      "RandomForest\n",
      "defeats = 9 equalities = 17 victories = 9\n",
      "XGBoost\n",
      "defeats = 11 equalities = 15 victories = 9\n"
     ]
    }
   ],
   "source": [
    "for regressor_name in regressor_names:\n",
    "    print(regressor_name)\n",
    "    print('defeats = ' + str(metrics_dict[regressor_name].count(-1)),\n",
    "         'equalities = ' + str(metrics_dict[regressor_name].count(0)),\n",
    "         'victories = ' + str(metrics_dict[regressor_name].count(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5ad0ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics_dict).to_csv(os.path.join(metrics_path, 'result.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
